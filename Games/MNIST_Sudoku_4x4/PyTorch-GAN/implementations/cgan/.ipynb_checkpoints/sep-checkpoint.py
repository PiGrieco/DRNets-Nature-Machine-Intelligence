{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "batch_size = 64\n",
    "latent_dim = 100\n",
    "n_classes = 10\n",
    "img_shape = (1, 32, 32)\n",
    "img_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim + n_classes, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        #print (\"label: \" labels)\n",
    "        #print (\"!!!!!!!!!!!!!!!1 \", self.label_emb(labels).size(), \" \", noise.size())\n",
    "        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "if torch.cuda.is_available():\n",
    "    print (\"use cuda\")\n",
    "    generator = generator.cuda()\n",
    "generator.load_state_dict(torch.load(\"models/G-180.model\"))\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../../data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starts\n",
      "0 8 775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dc874/miniconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/dc874/miniconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 51 38\n",
      "20 961 933\n",
      "30 448 679\n",
      "40 391 16\n",
      "50 744 174\n",
      "60 425 622\n",
      "70 254 198\n",
      "80 170 930\n",
      "90 470 655\n",
      "Initial Image\n"
     ]
    }
   ],
   "source": [
    "# Unsupervised sperate the image with dropout\n",
    "from skimage import data\n",
    "from skimage.transform import resize\n",
    "\n",
    "nums = 4\n",
    "\n",
    "class predictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(predictor, self).__init__()\n",
    "        #self.conv1 = torch.nn.Conv2d(1, 16, 3)\n",
    "        #self.conv2 = torch.nn.Conv2d(16, 8, 3)\n",
    "        self.fc1 = torch.nn.Linear(1024, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 512)\n",
    "        self.fc3 = torch.nn.Linear(512, nums)\n",
    "        self.fc4 = torch.nn.Linear(512, nums)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "    \n",
    "    def forward(self, x, ind1, ind2):\n",
    "        #x = F.relu(self.conv1(x))\n",
    "        #x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x1 = self.softmax(self.fc3(x)) * ind1\n",
    "        x2 = self.softmax(self.fc4(x)) * ind2\n",
    "        \n",
    "        return x1, x2\n",
    "\n",
    "class seprator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(seprator, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(1024, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 512)\n",
    "        self.fc3 = torch.nn.Linear(512, 512)\n",
    "        self.fc4 = torch.nn.Linear(512, 100 * nums * 2)\n",
    "    def forward(self, x):\n",
    "#         x = x.view(-1, 1024)\n",
    "#         x = 3.0 * F.tanh(self.fc1(x))\n",
    "#         x = 3.0 * F.tanh(self.fc2(x))\n",
    "#         x = 3.0 * F.tanh(self.fc3(x)) - 0.5\n",
    "#         x = x.view(1, 10, 100)\n",
    "        \n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = F.relu(self.fc3(x))\n",
    "        #x = 2.0 * F.tanh(self.fc4(x))\n",
    "        x = self.fc4(x)\n",
    "        x = x.view(2, nums, 100)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def entropy(x):\n",
    "    return -torch.sum(x * torch.log(x))\n",
    "\n",
    "def rescale(x):\n",
    "    x = x.reshape(16, 1, 28, 28)\n",
    "    x = np.transpose(x, (1, 2, 3, 0))\n",
    "    x = resize(x, (1, 32, 32, 16))\n",
    "    x = np.transpose(x, (3, 0, 1, 2))\n",
    "    for i in range(16):\n",
    "        x[i][0] = (x[i][0] - 0.5) / 0.5\n",
    "        #x[i] = F.normalize(torch.from_numpy(x[i]).float(), 0.5, 0.5).data.numpy()\n",
    "    #print (x.shape)\n",
    "    #print (x[1, 0, 12, :])\n",
    "    return x\n",
    "\n",
    "def show_sudoku(x1, x2, x_mix, name=\"1\"):\n",
    "    n_col = 4\n",
    "    n_row = 4\n",
    "    fig, axes = plt.subplots(n_row, n_col * 3, figsize = (3 *n_col, n_row))\n",
    "    for j in range(4):\n",
    "        for k in range(4):\n",
    "            axes[j][k].imshow(x1[j][k], cmap = \"gray\")\n",
    "            axes[j][4 + k].imshow(x2[j][k], cmap=\"gray\")\n",
    "            axes[j][8 + k].imshow(x_mix[j][k], cmap=\"gray\")\n",
    "    plt.show()\n",
    "            \n",
    "#for i, (imgs, labels) in enumerate(dataloader):\n",
    "sudoku = np.load(\"../../../4by4.npy\") #100, 16, 1, 28, 28\n",
    "sudoku5678 = np.load(\"../../../4by4_5678.npy\") #100, 16, 1, 28, 28\n",
    "ori_label = np.load(\"../../../4by4_labels.npy\") #100, 16\n",
    "ori_label5678 = np.load(\"../../../4by4_5678_labels.npy\") #100, 16\n",
    "\n",
    "n_data = sudoku.shape[0]\n",
    "#idx1, idx2 = 2, 31.0\n",
    "\n",
    "idx_pairs = []\n",
    "shuffled_list = np.arange(n_data)\n",
    "np.random.shuffle(shuffled_list)\n",
    "\n",
    "for i in range(n_data):\n",
    "    idx_pairs.append((i, shuffled_list[i]))\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "#print (\"Initial Image\")\n",
    "n_col = 4\n",
    "n_row = 4\n",
    "#show_sudoku(s1, s2, s_mix, \"s1\")\n",
    "lr = 0.0003\n",
    "printdrop_out__every = 1\n",
    "\n",
    "sep  = seprator()\n",
    "pred = predictor()\n",
    "if use_cuda:\n",
    "    sep = sep.cuda()\n",
    "    pred = pred.cuda()\n",
    "\n",
    "base1 = 1\n",
    "base2 = 5\n",
    "        \n",
    "print(\"Training Starts\")\n",
    "for _epoch_ in range(2000):\n",
    "    np.random.shuffle(idx_pairs)\n",
    "    sudoku_acc = 0\n",
    "    label_acc = 0\n",
    "    recon_loss = 0\n",
    "    cnt = 0\n",
    "    for (idx1, idx2) in idx_pairs:\n",
    "        if (cnt % 10 == 0):\n",
    "            print(cnt, idx1, idx2)\n",
    "        s1 = sudoku[idx1]\n",
    "        s2 = sudoku5678[idx2]\n",
    "        l1 = ori_label[idx1]\n",
    "        l2 = ori_label5678[idx2]\n",
    "        \n",
    "        s1 = rescale(s1)\n",
    "        s2 = rescale(s2)\n",
    "        s1 = s1.reshape(4, 4, 32, 32)\n",
    "        s2 = s2.reshape(4, 4, 32, 32)\n",
    "        s_mix = np.zeros(s1.shape)\n",
    "        for i in range(s1.shape[0]):\n",
    "            for j in range(s2.shape[1]):\n",
    "                s_mix[i, j] = mix(s1[i, j], s2[i, j])\n",
    "    \n",
    "        s_mix = np.reshape(s_mix, (16, 1, 32, 32))\n",
    "        pretrain_epoch = 100\n",
    "        \n",
    "        \n",
    "        epochs = 1\n",
    "        for ii in range(epochs):\n",
    "            s_mix = Variable(torch.tensor(s_mix).float(), requires_grad=False)\n",
    "            if use_cuda:\n",
    "                s_mix = s_mix.cuda()\n",
    "\n",
    "            if (ii < 0):\n",
    "                ind1 = np.random.randint(2, size = (s_mix.size(0), nums))\n",
    "                ind2 = np.random.randint(2, size = (s_mix.size(0), nums))\n",
    "            else:\n",
    "                ind1 = np.zeros((s_mix.size(0), nums)) + 1\n",
    "                ind2 = np.zeros((s_mix.size(0), nums)) + 1\n",
    "\n",
    "            ind1 = torch.tensor(ind1).float()\n",
    "            ind2 = torch.tensor(ind2).float()\n",
    "            if use_cuda:\n",
    "                ind1 = ind1.cuda()\n",
    "                ind2 = ind2.cuda()\n",
    "            labels1_distribution, labels2_distribution = pred(s_mix, ind1, ind2)\n",
    "\n",
    "\n",
    "            gen_labels1 = []\n",
    "            gen_labels2 = []\n",
    "            labels1 = labels1_distribution.cpu().data.numpy()\n",
    "            labels2 = labels2_distribution.cpu().data.numpy()\n",
    "            labels1_argmax = np.argmax(labels1, axis=1)\n",
    "            labels2_argmax = np.argmax(labels2, axis=1)\n",
    "\n",
    "            labels12 = np.concatenate([(labels1_argmax + base1).reshape(-1, 1), (labels2_argmax + base2).reshape(-1, 1)], axis = 1)\n",
    "            l12 = np.concatenate([l1.reshape(-1, 1), l2.reshape(-1, 1)], axis = 1)\n",
    "\n",
    "            acc = 0\n",
    "            for i in range(len(l12)):\n",
    "                if (labels12[i][0] == l12[i][0] and labels12[i][1] == l12[i][1]):\n",
    "                    acc += 1\n",
    "                elif (labels12[i][1] == l12[i][0] and labels12[i][0] == l12[i][1]):\n",
    "                    acc += 1\n",
    "            acc /= labels12.shape[0]\n",
    "\n",
    "\n",
    "            #print (labels1.shape)\n",
    "            for jj in range(labels1_distribution.size(0)):\n",
    "                #print (np.argmax(labels1_distribution[jj].data.numpy()))\n",
    "                for kk in range(4):\n",
    "                    #gen_labels1.append(Variable(torch.LongTensor([np.argmax(labels1_distribution[jj].data.numpy()) + base])))\n",
    "                    #gen_labels2.append(Variable(torch.LongTensor([np.argmax(labels2_distribution[jj].data.numpy()) + base])))\n",
    "                    if use_cuda:\n",
    "                        gen_labels1.append(Variable(torch.LongTensor([kk + base1]).cuda()))\n",
    "                        gen_labels2.append(Variable(torch.LongTensor([kk + base2]).cuda()))\n",
    "                    else:\n",
    "                        gen_labels1.append(Variable(torch.LongTensor([kk + base1])))\n",
    "                        gen_labels2.append(Variable(torch.LongTensor([kk + base2])))\n",
    "\n",
    "            z1 = []\n",
    "            z2 = []\n",
    "            for jj in range(4 * labels1_distribution.size(0)):\n",
    "                if (jj % 4) == 0:\n",
    "                    if use_cuda:\n",
    "                        zt = sep(torch.tensor(s_mix[int(jj / 4)].reshape(1, 1, 32, 32)).float().cuda())\n",
    "                    else:\n",
    "                        zt = sep(torch.tensor(s_mix[int(jj / 4)].reshape(1, 1, 32, 32)).float())\n",
    "                #z1.append(zt[0][gen_labels1[jj] - 1])\n",
    "                #z2.append(zt[1][gen_labels2[jj] - 1])\n",
    "                z1.append(zt[0][gen_labels1[jj] - base1])\n",
    "                z2.append(zt[1][gen_labels2[jj] - base2])\n",
    "            optimizer = torch.optim.Adam(list(pred.parameters()) + list(sep.parameters()), lr=lr)\n",
    "            optimizer.zero_grad()\n",
    "            #print (gen_labels1)\n",
    "            #gen_imgs1 = [generator(z1[jj], gen_labels1[jj]) for jj in range(labels1_distribution.size(0))]\n",
    "            #gen_imgs2 = [generator(z2[jj], gen_labels2[jj]) for jj in range(labels1_distribution.size(0))]\n",
    "\n",
    "            def prob_mix(idx, z, gen_label, label):\n",
    "                ret = None\n",
    "                for i in range(idx, idx + nums):\n",
    "                    mix = generator(z[i], gen_label[i])\n",
    "                    if ret is None:\n",
    "                        ret = label[int(idx / nums)][i - idx] * mix\n",
    "                    else:\n",
    "                        ret = ret + label[int(idx / nums)][i - idx] * mix\n",
    "                return ret\n",
    "\n",
    "            gen_imgs1 = [prob_mix(jj, z1, gen_labels1, labels1_distribution) for jj in range(0, nums * labels1_distribution.size(0), 4)]\n",
    "            gen_imgs2 = [prob_mix(jj, z2, gen_labels2, labels2_distribution) for jj in range(0, nums * labels1_distribution.size(0), 4)]\n",
    "            gen_mix = [torch.max(gen_imgs1[jj], gen_imgs2[jj]).squeeze() for jj in range(labels1_distribution.size(0))]\n",
    "            cri = torch.nn.MSELoss()\n",
    "            #loss = cri(gen_mix, torch.from_numpy(img_mix).float())\n",
    "            loss_recon = 0.\n",
    "            #print (\"gen_mix: \", gen_mix[jj].size())\n",
    "            for jj in range(labels1_distribution.size(0)):\n",
    "                loss_recon += cri(s_mix[jj][0], gen_mix[jj])\n",
    "            loss_recon /= (1.0 * labels1_distribution.size(0))\n",
    "            entropy_cell = 0.\n",
    "            for jj in range(labels1_distribution.size(0)):\n",
    "                entropy_cell += entropy(labels1_distribution[jj]) + entropy(labels2_distribution[jj])\n",
    "            entropy_cell /= (2.0 * labels1_distribution.size(0))\n",
    "\n",
    "            sqr_size = int(np.sqrt(labels1_distribution.size(0)))\n",
    "            labels1_distribution = labels1_distribution.view(sqr_size, sqr_size, sqr_size)\n",
    "            labels2_distribution = labels2_distribution.view(sqr_size, sqr_size, sqr_size)\n",
    "            entropy_row = 0.\n",
    "            for jj in range(sqr_size):\n",
    "                #print (\"!! \", torch.mean(labels1_distribution[jj, :, :], dim=0).size())\n",
    "                entropy_row += entropy(torch.mean(labels1_distribution[jj, :, :], dim=0)) +\\\n",
    "                    entropy(torch.mean(labels2_distribution[jj, :, :], dim=0))\n",
    "\n",
    "            entropy_row /= (2.0 * sqr_size)\n",
    "            entropy_col = 0.\n",
    "            for jj in range(sqr_size):\n",
    "                #print (\"! \", labels1_distribution[].data.numpy())\n",
    "                #print (\"!! \", torch.mean(labels1_distribution[:, jj, :], dim=1).data.numpy())\n",
    "                entropy_col += entropy(torch.mean(labels1_distribution[:, jj, :], dim=0)) +\\\n",
    "                    entropy(torch.mean(labels2_distribution[:, jj, :], dim=0))\n",
    "            entropy_col /= (2.0 * sqr_size)\n",
    "            entropy_block = 0.\n",
    "            sqrsqr_size = int(np.sqrt(sqr_size))\n",
    "            for jj in range(0, sqr_size, sqrsqr_size):\n",
    "                for kk in range(0, sqr_size, sqrsqr_size):\n",
    "                    entropy_block += entropy(torch.mean(labels1_distribution[jj:jj + sqrsqr_size, kk:kk + sqrsqr_size, :]\\\n",
    "                                                        .contiguous().view(sqr_size, sqr_size), dim=0))\\\n",
    "                                     +entropy(torch.mean(labels2_distribution[jj:jj + sqrsqr_size, kk:kk + sqrsqr_size, :]\\\n",
    "                                                        .contiguous().view(sqr_size, sqr_size), dim=0))\n",
    "            entropy_block /= (2.0 * sqr_size)\n",
    "\n",
    "            scale_recon = 0.005\n",
    "            scale_cell = 1.5\n",
    "            scale_entropy = 1.0\n",
    "            #, entropy_block.item())\n",
    "            #loss = scale_recon * loss_recon + scale_cell * entropy_cell - entropy_row - entropy_col - entropy_block\n",
    "            keep_p = 1.0\n",
    "            drop_out_recon = torch.nn.Dropout(p=1.0 - keep_p)\n",
    "            drop_out_cell = torch.nn.Dropout(p=0.0)\n",
    "            drop_out_rowcol = torch.nn.Dropout(p=0.5)\n",
    "            drop_out_block = torch.nn.Dropout(p=0.5)\n",
    "           # print (\"total_loss: %f, loss_recon: %f, entropy_cell: %f, entropy_row: %f, entropy_col: %f, entropy_block: %f\" \\\n",
    "           #        % (loss.item(), scale_recon * loss_recon.item(), scale_cell * entropy_cell.item(), scale_entropy * entropy_row.item(),\\\n",
    "           #            scale_entropy * entropy_col.item(), scale_entropy * entropy_block.item()))\n",
    "\n",
    "            loss_recon = drop_out_recon(loss_recon)\n",
    "            entropy_cell = drop_out_cell(entropy_cell)\n",
    "            entropy_row = drop_out_rowcol(entropy_row)\n",
    "            entropy_col = drop_out_rowcol(entropy_col)\n",
    "            entropy_block = drop_out_block(entropy_block)\n",
    "\n",
    "            if (_epoch_ < 10):\n",
    "                loss = scale_recon * loss_recon\n",
    "            else:\n",
    "                #loss = scale_recon * loss_recon\n",
    "                loss = scale_recon * loss_recon + 0.5 * entropy_cell - 1.0 * scale_entropy  *(entropy_row + entropy_col + entropy_block)\n",
    "\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #if ii % 100 == 0:\n",
    "            #    print (\"Iteration %d: loss: %f\" % (ii, loss.item()))\n",
    "            #    gen_imgs1_numpy = np.concatenate([item.cpu().data.numpy() for item in gen_imgs1])\n",
    "            #    gen_imgs1_numpy = np.reshape(gen_imgs1_numpy, (4, 4, 32, 32))\n",
    "            #    gen_imgs2_numpy = np.concatenate([item.cpu().data.numpy() for item in gen_imgs2])\n",
    "            #    gen_imgs2_numpy = np.reshape(gen_imgs2_numpy, (4, 4, 32, 32))\n",
    "            #    gen_mix_numpy = np.concatenate([item.cpu().data.numpy() for item in gen_mix])\n",
    "            #    gen_mix_numpy = np.reshape(gen_mix_numpy, (4, 4, 32, 32))\n",
    "                #show_sudoku(gen_imgs1_numpy, gen_imgs2_numpy, gen_mix_numpy)\n",
    "                #print (gen_imgs1[0].size(), \" \", len(gen_imgs1))\n",
    "                \n",
    "        label_acc += float(acc)\n",
    "        sudoku_acc += float(acc == 1.0)\n",
    "        recon_loss += scale_recon * loss_recon.item()\n",
    "        cnt += 1\n",
    "        if (cnt == 100):\n",
    "            label_acc /= cnt\n",
    "            sudoku_acc /= cnt\n",
    "            recon_loss /= cnt\n",
    "            print (\"Initial Image\")\n",
    "            show_sudoku(s1, s2, np.reshape(s_mix, (4, 4, 32, 32)), \"s1\")\n",
    "            \n",
    "            print (\"epoch = %d, iter-%d, acc= %f\" % (_epoch_, ii, acc))\n",
    "            for i in range(4):\n",
    "                for j in range(4):\n",
    "                    print(labels1_argmax[i*4 + j] + base1, end = \",\")\n",
    "                print(\" \", end = \"\")\n",
    "\n",
    "                for j in range(4):\n",
    "                    print(labels2_argmax[i*4 + j] + base2, end = \",\")\n",
    "                print(\" \", end = \"\")\n",
    "                \n",
    "                for j in range(4):\n",
    "                    print(l1[i*4 + j], end = \",\")\n",
    "                print(\" \", end = \"\")\n",
    "\n",
    "                for j in range(4):\n",
    "                    print(l2[i*4 + j], end = \",\")\n",
    "                print(\"\")\n",
    "                \n",
    "                \n",
    "            print (\"Iteration %d: loss: %f\" % (ii, loss.item()))\n",
    "            gen_imgs1_numpy = np.concatenate([item.cpu().data.numpy() for item in gen_imgs1])\n",
    "            gen_imgs1_numpy = np.reshape(gen_imgs1_numpy, (4, 4, 32, 32))\n",
    "            gen_imgs2_numpy = np.concatenate([item.cpu().data.numpy() for item in gen_imgs2])\n",
    "            gen_imgs2_numpy = np.reshape(gen_imgs2_numpy, (4, 4, 32, 32))\n",
    "            gen_mix_numpy = np.concatenate([item.cpu().data.numpy() for item in gen_mix])\n",
    "            gen_mix_numpy = np.reshape(gen_mix_numpy, (4, 4, 32, 32))\n",
    "            show_sudoku(gen_imgs1_numpy, gen_imgs2_numpy, gen_mix_numpy)\n",
    "            print(\"sudoku_acc = %f, label_acc = %f, recon_loss = %f\"%(sudoku_acc, label_acc, recon_loss))\n",
    "            cnt = 0\n",
    "            label_acc = 0\n",
    "            sudoku_acc = 0\n",
    "            recon_loss = 0\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix(a, b):\n",
    "    ret = np.zeros(a.shape)\n",
    "    for i in range(a.shape[0]):\n",
    "        for j in range(a.shape[1]):\n",
    "            ret[i, j] = max(a[i, j], b[i, j])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
